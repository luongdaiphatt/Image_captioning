{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:43:57.949308Z",
     "iopub.status.busy": "2024-12-21T06:43:57.948729Z",
     "iopub.status.idle": "2024-12-21T06:43:57.953120Z",
     "shell.execute_reply": "2024-12-21T06:43:57.952445Z",
     "shell.execute_reply.started": "2024-12-21T06:43:57.949273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTModel, AutoTokenizer, AutoModelForCausalLM, AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:43:57.954789Z",
     "iopub.status.busy": "2024-12-21T06:43:57.954597Z",
     "iopub.status.idle": "2024-12-21T06:44:07.889542Z",
     "shell.execute_reply": "2024-12-21T06:44:07.888718Z",
     "shell.execute_reply.started": "2024-12-21T06:43:57.954773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/vitngquang/uit-viic-v1-0-vietnamese-image-captioning\n",
      "License(s): other\n",
      "Downloading uit-viic-v1-0-vietnamese-image-captioning.zip to /kaggle/working\n",
      "100%|███████████████████████████████████████| 1.23G/1.23G [00:08<00:00, 183MB/s]\n",
      "100%|███████████████████████████████████████| 1.23G/1.23G [00:08<00:00, 152MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d vitngquang/uit-viic-v1-0-vietnamese-image-captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:07.891632Z",
     "iopub.status.busy": "2024-12-21T06:44:07.891299Z",
     "iopub.status.idle": "2024-12-21T06:44:17.745895Z",
     "shell.execute_reply": "2024-12-21T06:44:17.744889Z",
     "shell.execute_reply.started": "2024-12-21T06:44:07.891610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!unzip -q uit-viic-v1-0-vietnamese-image-captioning.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.747282Z",
     "iopub.status.busy": "2024-12-21T06:44:17.746972Z",
     "iopub.status.idle": "2024-12-21T06:44:17.752003Z",
     "shell.execute_reply": "2024-12-21T06:44:17.751215Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.747253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path + 'captions.txt', 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data = [line.split('\\t', 1) for line in lines]\n",
    "    df = pd.DataFrame(data, columns=[\"image_path\", \"caption\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.753003Z",
     "iopub.status.busy": "2024-12-21T06:44:17.752793Z",
     "iopub.status.idle": "2024-12-21T06:44:17.768718Z",
     "shell.execute_reply": "2024-12-21T06:44:17.767822Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.752984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/working/dataset' # nếu dùng kaggle\n",
    "train_path = dataset_path + '/train/'\n",
    "val_path = dataset_path + '/val/'\n",
    "test_path = dataset_path + '/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.769942Z",
     "iopub.status.busy": "2024-12-21T06:44:17.769659Z",
     "iopub.status.idle": "2024-12-21T06:44:17.818432Z",
     "shell.execute_reply": "2024-12-21T06:44:17.817664Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.769914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = load_data(train_path)\n",
    "df_val = load_data(val_path)\n",
    "df_test = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.821327Z",
     "iopub.status.busy": "2024-12-21T06:44:17.821104Z",
     "iopub.status.idle": "2024-12-21T06:44:17.826266Z",
     "shell.execute_reply": "2024-12-21T06:44:17.825540Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.821307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(df):\n",
    "    df_preprocessed = df.copy()\n",
    "    df_preprocessed['caption'] = df_preprocessed['caption'].apply(lambda x: x.lower())\n",
    "    df_preprocessed['caption'] = df_preprocessed['caption'].apply(lambda x: x.replace(\"[^A-Za-z]\",\"\"))\n",
    "    df_preprocessed['caption'] = df_preprocessed['caption'].apply(lambda x: x.replace(\"\\s+\",\" \"))\n",
    "    df_preprocessed['caption'] = df_preprocessed['caption'].apply(lambda x: \" \".join([word for word in x.split() if len(word)>1]))\n",
    "    df_preprocessed['caption'] = \"startseq \"+df_preprocessed['caption']+\" endseq\"\n",
    "    df_preprocessed['image_path'] = df_preprocessed['image_path'].str.replace('^/dataset', '', regex=True)\n",
    "    df_preprocessed['image_path'] = dataset_path + df_preprocessed['image_path']\n",
    "    return df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.828201Z",
     "iopub.status.busy": "2024-12-21T06:44:17.827960Z",
     "iopub.status.idle": "2024-12-21T06:44:17.950863Z",
     "shell.execute_reply": "2024-12-21T06:44:17.949996Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.828183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train_preprocessed = text_preprocessing(df_train)\n",
    "df_val_preprocessed = text_preprocessing(df_val)\n",
    "df_test_preprocessed = text_preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.952105Z",
     "iopub.status.busy": "2024-12-21T06:44:17.951858Z",
     "iopub.status.idle": "2024-12-21T06:44:17.956282Z",
     "shell.execute_reply": "2024-12-21T06:44:17.955511Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.952084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTModel,ViTImageProcessor\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:17.957420Z",
     "iopub.status.busy": "2024-12-21T06:44:17.957173Z",
     "iopub.status.idle": "2024-12-21T06:44:20.785193Z",
     "shell.execute_reply": "2024-12-21T06:44:20.784261Z",
     "shell.execute_reply.started": "2024-12-21T06:44:17.957402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b3a43e3da4113861d6b610ba79d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611722f57b9447cda29bdba07f4fe1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7976dec53245dab86482414195c626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải mô hình và bộ trích xuất đặc trưng ViT\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:44:20.786294Z",
     "iopub.status.busy": "2024-12-21T06:44:20.786066Z",
     "iopub.status.idle": "2024-12-21T06:57:45.557438Z",
     "shell.execute_reply": "2024-12-21T06:57:45.556274Z",
     "shell.execute_reply.started": "2024-12-21T06:44:20.786274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [13:24<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đặc trưng đã được trích xuất thành công!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Danh sách ảnh (thay bằng df_train_preprocessed['image_path'] và df_val_preprocessed['image_path'])\n",
    "all_images = df_train_preprocessed['image_path'].unique().tolist() + df_val_preprocessed['image_path'].unique().tolist()\n",
    "\n",
    "# Kích thước ảnh đầu vào\n",
    "img_size = 224\n",
    "\n",
    "# Dictionary để lưu trữ đặc trưng của từng ảnh\n",
    "features = {}\n",
    "\n",
    "# Duyệt qua tất cả các ảnh\n",
    "for image_path in tqdm(all_images):\n",
    "    # Mở ảnh và tiền xử lý\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Nếu ảnh là grayscale, chuyển nó thành RGB\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    img = img.resize((img_size, img_size))  # Điều chỉnh kích thước ảnh\n",
    "    \n",
    "    # Tiền xử lý ảnh: chuẩn hóa và chuyển sang tensor\n",
    "    inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "    \n",
    "    # Trích xuất đặc trưng từ mô hình ViT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Lấy thông tin đặc trưng từ đầu ra (trong trường hợp này là 'last_hidden_state')\n",
    "    feature = outputs.last_hidden_state.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Lưu đặc trưng vào dictionary\n",
    "    features[image_path] = feature\n",
    "\n",
    "# Lưu các đặc trưng vào tệp hoặc tiếp tục xử lý\n",
    "print(\"Đặc trưng đã được trích xuất thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:57:45.558859Z",
     "iopub.status.busy": "2024-12-21T06:57:45.558533Z",
     "iopub.status.idle": "2024-12-21T06:57:49.575272Z",
     "shell.execute_reply": "2024-12-21T06:57:49.574350Z",
     "shell.execute_reply.started": "2024-12-21T06:57:45.558825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"features.npz\", **features) # lưu features trích xuất từ các images về máy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:57:49.576523Z",
     "iopub.status.busy": "2024-12-21T06:57:49.576199Z",
     "iopub.status.idle": "2024-12-21T06:57:56.821297Z",
     "shell.execute_reply": "2024-12-21T06:57:56.820377Z",
     "shell.execute_reply.started": "2024-12-21T06:57:49.576490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1c28f49f6a45f282ba0918d1a17ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67ec244b9774a8da862b8230b8b0a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/854k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121f222c3cc04bbdbfd4fc7f67f6d6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/512k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc312bd087f4c038126cfac7eb6d934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c0f70757f643dc8451e4ac387adec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa8b91d952409bbcb58a793e323b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2a344ca4ed4f0f91b77d844de901e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a715b0f35c4b53aa310f864b92f0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"NlpHUST/gpt2-vietnamese\")\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(\"NlpHUST/gpt2-vietnamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:57:56.822493Z",
     "iopub.status.busy": "2024-12-21T06:57:56.822253Z",
     "iopub.status.idle": "2024-12-21T06:57:56.853795Z",
     "shell.execute_reply": "2024-12-21T06:57:56.852886Z",
     "shell.execute_reply.started": "2024-12-21T06:57:56.822472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiểm tra đặc trưng từ file đã lưu\n",
    "features = np.load(\"features.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:57:56.855115Z",
     "iopub.status.busy": "2024-12-21T06:57:56.854828Z",
     "iopub.status.idle": "2024-12-21T06:58:14.618929Z",
     "shell.execute_reply": "2024-12-21T06:58:14.618126Z",
     "shell.execute_reply.started": "2024-12-21T06:57:56.855082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Chuẩn bị dữ liệu: Kết hợp embedding hình ảnh với caption\n",
    "image_features = []\n",
    "captions = []\n",
    "\n",
    "for image_path, caption in zip(df_train_preprocessed['image_path'], df_train_preprocessed['caption']):\n",
    "    if image_path in features:\n",
    "        image_features.append(features[image_path])\n",
    "        captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:58:14.620111Z",
     "iopub.status.busy": "2024-12-21T06:58:14.619817Z",
     "iopub.status.idle": "2024-12-21T06:58:15.580311Z",
     "shell.execute_reply": "2024-12-21T06:58:15.579349Z",
     "shell.execute_reply.started": "2024-12-21T06:58:14.620081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Gán eos_token làm pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize captions\n",
    "inputs = tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:58:15.581478Z",
     "iopub.status.busy": "2024-12-21T06:58:15.581257Z",
     "iopub.status.idle": "2024-12-21T06:58:16.189307Z",
     "shell.execute_reply": "2024-12-21T06:58:16.188369Z",
     "shell.execute_reply.started": "2024-12-21T06:58:15.581460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nếu thêm [PAD], hãy đảm bảo resize embedding\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "gpt2_model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:58:16.190268Z",
     "iopub.status.busy": "2024-12-21T06:58:16.190039Z",
     "iopub.status.idle": "2024-12-21T06:58:16.200034Z",
     "shell.execute_reply": "2024-12-21T06:58:16.199218Z",
     "shell.execute_reply.started": "2024-12-21T06:58:16.190249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Kích thước embedding\n",
    "image_dim = 768  # Kích thước đầu ra của ViT\n",
    "gpt2_dim = gpt2_model.config.hidden_size\n",
    "\n",
    "# Mạng kết nối\n",
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MappingNetwork, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "mapping_network = MappingNetwork(image_dim, gpt2_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:58:16.201116Z",
     "iopub.status.busy": "2024-12-21T06:58:16.200858Z",
     "iopub.status.idle": "2024-12-21T07:03:06.968396Z",
     "shell.execute_reply": "2024-12-21T07:03:06.967380Z",
     "shell.execute_reply.started": "2024-12-21T06:58:16.201086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-250aa8594601>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  image_features = torch.tensor(image_features)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Chuẩn bị DataLoader\n",
    "image_features = torch.tensor(image_features)\n",
    "captions_input_ids = inputs['input_ids']\n",
    "dataset = TensorDataset(image_features, captions_input_ids)\n",
    "\n",
    "# Tối ưu hóa\n",
    "optimizer = AdamW(list(mapping_network.parameters()) + list(gpt2_model.parameters()), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T07:03:06.969751Z",
     "iopub.status.busy": "2024-12-21T07:03:06.969416Z",
     "iopub.status.idle": "2024-12-21T07:03:06.979703Z",
     "shell.execute_reply": "2024-12-21T07:03:06.978909Z",
     "shell.execute_reply.started": "2024-12-21T07:03:06.969718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T07:03:06.980826Z",
     "iopub.status.busy": "2024-12-21T07:03:06.980566Z",
     "iopub.status.idle": "2024-12-21T07:03:07.062117Z",
     "shell.execute_reply": "2024-12-21T07:03:07.061133Z",
     "shell.execute_reply.started": "2024-12-21T07:03:06.980796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.amp import GradScaler  # Sử dụng GradScaler từ torch.amp\n",
    "\n",
    "# Optimizer và scaler\n",
    "optimizer = AdamW(gpt2_model.parameters(), lr=1e-4)\n",
    "\n",
    "scaler = GradScaler(device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T07:03:07.065943Z",
     "iopub.status.busy": "2024-12-21T07:03:07.065653Z",
     "iopub.status.idle": "2024-12-21T07:03:07.074806Z",
     "shell.execute_reply": "2024-12-21T07:03:07.073978Z",
     "shell.execute_reply.started": "2024-12-21T07:03:07.065921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scaler, path=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict() if scaler else None,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch + 1} to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T07:03:07.075968Z",
     "iopub.status.busy": "2024-12-21T07:03:07.075724Z",
     "iopub.status.idle": "2024-12-21T13:50:54.584426Z",
     "shell.execute_reply": "2024-12-21T13:50:54.583317Z",
     "shell.execute_reply.started": "2024-12-21T07:03:07.075944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 211/211 [1:21:17<00:00, 23.11s/it, loss=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 1 to checkpoint.pth\n",
      "Epoch 1 completed.\n",
      "Epoch 1 - Loss: 0.45360246300697327\n",
      "Starting Epoch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 211/211 [1:21:32<00:00, 23.19s/it, loss=0.373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 2 to checkpoint.pth\n",
      "Epoch 2 completed.\n",
      "Epoch 2 - Loss: 0.37283942103385925\n",
      "Starting Epoch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 211/211 [1:22:08<00:00, 23.36s/it, loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 3 to checkpoint.pth\n",
      "Epoch 3 completed.\n",
      "Epoch 3 - Loss: 0.39291220903396606\n",
      "Starting Epoch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 211/211 [1:20:50<00:00, 22.99s/it, loss=0.304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 4 to checkpoint.pth\n",
      "Epoch 4 completed.\n",
      "Epoch 4 - Loss: 0.3038335144519806\n",
      "Starting Epoch 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 211/211 [1:21:44<00:00, 23.25s/it, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 5 to checkpoint.pth\n",
      "Epoch 5 completed.\n",
      "Epoch 5 - Loss: 0.26789599657058716\n"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast\n",
    "for epoch in range(5):\n",
    "    print(f\"Starting Epoch {epoch + 1}...\")\n",
    "    dataloader_iter = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (img_feat, caption_ids) in dataloader_iter:\n",
    "        try:\n",
    "            with autocast(device_type='cuda'):\n",
    "                seq_len = caption_ids.shape[1]\n",
    "                img_embedding = mapping_network(img_feat)\n",
    "                img_embedding = img_embedding[:, :seq_len, :]\n",
    "                caption_embedding = gpt2_model.transformer.wte(caption_ids)\n",
    "                inputs_embeds = torch.cat((img_embedding, caption_embedding), dim=1)\n",
    "                labels = torch.cat((\n",
    "                    torch.full((img_embedding.shape[0], img_embedding.shape[1]), -100, device=caption_ids.device),\n",
    "                    caption_ids\n",
    "                ), dim=1)\n",
    "\n",
    "                outputs = gpt2_model(inputs_embeds=inputs_embeds, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            dataloader_iter.set_description(f\"Epoch {epoch + 1}\")\n",
    "            dataloader_iter.set_postfix(loss=loss.item())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Batch {i + 1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Lưu checkpoint sau mỗi epoch\n",
    "    save_checkpoint(epoch, gpt2_model, optimizer, scaler, path=\"checkpoint.pth\")\n",
    "    print(f\"Epoch {epoch + 1} completed.\")\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_preprocessed['caption'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loaded_data = np.load(\"/kaggle/working/features.npz\", allow_pickle=True)\n",
    "features = dict(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_preprocessed['caption'] = df_test_preprocessed['caption'].str.replace(r'^startseq ', '', regex=True)\n",
    "df_test_preprocessed['caption'] = df_test_preprocessed['caption'].str.replace(r' endseq$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_merge = df_test_preprocessed.groupby('image_path')['caption'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for index,record in df_test_merge.iterrows():\n",
    "    img = load_img(record['image_path'],target_size=(224,224))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255.\n",
    "\n",
    "    caption = predict_caption(gpt2_model, record['image_path'], tokenizer, max_length, features)\n",
    "    df_test_merge.loc[index,'predict'] = caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_merge['predict'] = df_test_merge['predict'].str.replace(r'^startseq ', '', regex=True)\n",
    "df_test_merge['predict'] = df_test_merge['predict'].str.replace(r' endseq$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_bleu_scores(row):\n",
    "    reference = [caption.split() for caption in row['caption']]\n",
    "    prediction = row['predict'].split()\n",
    "\n",
    "    smoothie = SmoothingFunction().method4\n",
    "\n",
    "    bleu_1 = sentence_bleu(reference, prediction, weights=(1.0, 0, 0, 0), smoothing_function=smoothie)\n",
    "    bleu_2 = sentence_bleu(reference, prediction, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
    "    bleu_3 = sentence_bleu(reference, prediction, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothie)\n",
    "    bleu_4 = sentence_bleu(reference, prediction, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "\n",
    "    return pd.Series([bleu_1, bleu_2, bleu_3, bleu_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test_merge[['bleu_1', 'bleu_2', 'bleu_3', 'bleu_4']] = df_test_merge.apply(calculate_bleu_scores, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3878874,
     "sourceId": 6735684,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6310155,
     "sourceId": 10209876,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
